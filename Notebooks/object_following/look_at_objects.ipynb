{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/tproffen/SmartRobotCamp/master/Notebooks/Jetbot/ObjectFollow/mscoco_complete_label_map.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow an object\n",
    "\n",
    "This is very simular to the object detection. Look at the comments to see the additional code. We need to select an object type to follow. To figure out the index, check you [this file](https://github.com/tensorflow/models/blob/master/research/object_detection/data/mscoco_complete_label_map.pbtxt). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import ObjectDetector\n",
    "\n",
    "model = ObjectDetector('ssd_mobilenet_v2_coco.engine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Camera\n",
    "from jetbot import bgr8_to_jpeg\n",
    "from jetbot import Robot\n",
    "\n",
    "camera = Camera.instance(width=300, height=300)\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create some more widgets to control speeds and to set the central object to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "label_widget = widgets.IntText(value=47, description='tracked label')\n",
    "cx_widget = widgets.FloatText(value=0, description='cx')\n",
    "cy_widget = widgets.FloatText(value=0, description='cy')\n",
    "width_widget = widgets.FloatText(value=0, description='width')\n",
    "\n",
    "tolerance_widget = widgets.FloatSlider(description='tolerance', min=0.05, max=0.5, value=0.10, step=0.01)\n",
    "speed_widget = widgets.FloatSlider(description='speed', min=0.05, max=0.5, value=0.10, step=0.01)\n",
    "\n",
    "display(image_widget, label_widget, cx_widget, cy_widget, width_widget, tolerance_widget, speed_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "descriptions=[]\n",
    "\n",
    "with open('mscoco_complete_label_map.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    for p in data['items']:\n",
    "        descriptions.append(p['display_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional code below is added to find the center of the object to follow and use that to determine how to turn the robot, so it keeps looking at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "width = int(image_widget.width)\n",
    "height = int(image_widget.height)\n",
    "\n",
    "def drawBoundingBox(imgcv,box,label,color):\n",
    "    x1,y1,x2,y2 = (int(width * box[0]), int(height * box[1]), int(width * box[2]), int(height * box[3]))\n",
    "    cv2.rectangle(imgcv,(x1,y1),(x2,y2),color,2)\n",
    "    labelSize=cv2.getTextSize(label,cv2.FONT_HERSHEY_COMPLEX,0.5,2)\n",
    "    _x1 = x1\n",
    "    _y1 = y1\n",
    "    _x2 = x1+labelSize[0][0]\n",
    "    _y2 = y1-int(labelSize[0][1])\n",
    "    cv2.rectangle(imgcv,(_x1,_y1),(_x2,_y2),color,cv2.FILLED)\n",
    "    cv2.putText(imgcv,label,(x1,y1),cv2.FONT_HERSHEY_COMPLEX,0.5,(255,255,255),1)\n",
    "    return imgcv\n",
    "    \n",
    "def detection_center(detection):\n",
    "    \"\"\"Computes the center x, y coordinates of the object\"\"\"\n",
    "    bbox = detection['bbox']\n",
    "    center_x = (bbox[0] + bbox[2]) / 2.0 - 0.5\n",
    "    center_y = (bbox[1] + bbox[3]) / 2.0 - 0.5\n",
    "    return (center_x, center_y)\n",
    "    \n",
    "def norm(vec):\n",
    "    \"\"\"Computes the length of the 2D vector\"\"\"\n",
    "    return np.sqrt(vec[0]**2 + vec[1]**2)\n",
    "\n",
    "def closest_detection(detections):\n",
    "    \"\"\"Finds the detection closest to the image center\"\"\"\n",
    "    closest_detection = None\n",
    "    for det in detections:\n",
    "        center = detection_center(det)\n",
    "        if closest_detection is None:\n",
    "            closest_detection = det\n",
    "        elif norm(detection_center(det)) < norm(detection_center(closest_detection)):\n",
    "            closest_detection = det\n",
    "    return closest_detection\n",
    "\n",
    "def execute(change):\n",
    "    image = change['new']\n",
    "    \n",
    "    # compute all detected objects\n",
    "    detections = model(image)\n",
    "    \n",
    "    # draw all detections on image\n",
    "    \n",
    "    for det in detections[0]:\n",
    "        image=drawBoundingBox(image,det['bbox'],descriptions[det['label']],(255,0,0))\n",
    "\n",
    "    # select detections that match selected class label\n",
    "    matching_detections = [d for d in detections[0] if d['label'] == int(label_widget.value)]\n",
    "    \n",
    "    # get detection closest to center of field of view and draw it\n",
    "    det = closest_detection(matching_detections)\n",
    "    if det is not None:\n",
    "        image=drawBoundingBox(image,det['bbox'],descriptions[det['label']],(0,0,255))\n",
    "        center = detection_center(det)\n",
    "        width = det['bbox'][2] - det['bbox'][0]\n",
    "        cx_widget.value=center[0]\n",
    "        cy_widget.value=center[1]\n",
    "        width_widget.value=width\n",
    "        \n",
    "        limit=float(tolerance_widget.value)\n",
    "        speed=float(speed_widget.value)\n",
    "\n",
    "        # turn the robot\n",
    "        if center[0] > limit:\n",
    "            pass\n",
    "            robot.set_motors( speed,-speed)\n",
    "        elif center[0] < -limit:\n",
    "            pass\n",
    "            robot.set_motors(-speed, speed)\n",
    "        else:\n",
    "            pass\n",
    "            robot.stop()\n",
    "    else:\n",
    "        pass\n",
    "        robot.stop()\n",
    "    \n",
    "    # update image widget\n",
    "    image_widget.value = bgr8_to_jpeg(image)\n",
    "    \n",
    "execute({'new': camera.value})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This again will run the code for every camera frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve_all()\n",
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to stop following the object :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve_all()\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
